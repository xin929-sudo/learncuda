#include<stdio.h>
#include<cuda_runtime.h>
#include<limits.h>

// å®å®šä¹‰ï¼šåŒ…è£¹å‡½æ•°è°ƒç”¨ï¼Œæ£€æŸ¥è¿”å›å€¼
#define CUDA_CHECK(call) \
do { \
    const cudaError_t error = call; \
    if (error != cudaSuccess) { \
        fprintf(stderr, "Error: %s:%d, ", __FILE__, __LINE__); \
        fprintf(stderr, "code: %d, reason: %s\n", error, cudaGetErrorString(error)); \
        exit(1); \
    } \
} while (0)

// cpu version find max
int findMaxCpu(int* data,int n) {
    int max_val = INT_MIN;
    for(int i = 0 ; i < n; ++i) {
        if(data[i] > max_val) {
            max_val = data[i];
        }
    }
    return max_val;
}

// gpu version :navive cal max
__global__ void findMaxGpu_native(int* data,int n,int *result) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    int local_max = INT_MIN;
    
    for(int i = tid; i < n; i += stride) {
        if(data[i] > local_max) {
            local_max = data[i];
        }
    }
    atomicMax(result,local_max);
}

__global__ void findMaxGpu_shared(int *data,int n,int *result) {
    // 1.åˆ†é…å…±äº«å†…å­˜
    extern __shared__ int shared_data[];
    
    // çº¿ç¨‹ç´¢å¼•
    int tid = threadIdx.x; // blockå†…çº¿ç¨‹ç´¢å¼•ï¼ˆ0 ~ blockDim.x - 1)
    int gid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    
    // 2.æ¯ä¸ªçº¿ç¨‹æ‰¾è‡ªå·±è´Ÿè´£æ•°æ®çš„æœ€å¤§å€¼
    int local_max = INT_MIN;
    for(int i = gid; i < n; i += stride) {
        if(data[i] > local_max) {
            local_max = data[i];
        }
    }
    
    // å†™å…¥å…±äº«å†…å­˜
    shared_data[tid] = local_max;
    // åŒæ­¥
    __syncthreads();

    // 3.å½’çº¦æ ‘ï¼šåœ¨blockå†…æ‰¾æœ€å¤§å€¼
    for (int offset = blockDim.x / 2; offset > 0; offset >>= 1)
    {
        if(tid < offset) {
            // æ¯”è¾ƒæ›´æ–°
            if(shared_data[tid + offset] > shared_data[tid]) {
                shared_data[tid] = shared_data[tid + offset];
            }
        }
        // åŒæ­¥ï¼ç¡®ä¿å½“å‰å±‚çš„æ¯”è¾ƒéƒ½å®Œæˆäº†
        __syncthreads();
    }
    // 4.blockçš„ä»£è¡¨ï¼ˆçº¿ç¨‹0ï¼‰æ›´æ–°å…¨å±€ç»“æœ
    if(tid == 0) {
        atomicMax(result,shared_data[0]);
    }
    
}

#define WARP_SIZE   32
__global__ void findMaxGpu_warp_shuffle(int *data,int n,int *result) {

    int tid = threadIdx.x;
    int gid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // è®¡ç®—warpç›¸å…³ä¿¡æ¯
    int lane = tid % WARP_SIZE;
    int warpId = tid / WARP_SIZE;

    // step1:æ¯ä¸ªçº¿ç¨‹æ‰¾åˆ°è‡ªå·±è´Ÿè´£æ•°æ®çš„æœ€å¤§å€¼
    int local_max = INT_MIN;
    for(int i = gid; i < n; i += stride) {
        if(data[i] > local_max) {
            local_max = data[i];
        }
    }


    // step2 : warp shuffle reduce(warpå†…å½’çº¦)
    // åˆ©ç”¨shuffleæŒ‡ä»¤ï¼Œåœ¨å¯„å­˜å™¨å±‚é¢äº¤æ¢æ•°æ®æ— éœ€å…±äº«å†…å­˜
    // ç¬¬ 1 è½®ï¼šoffset = 16
    // ä»£ç æ‰§è¡Œï¼šneighbor = __shfl_down_sync(..., local_max, 16)

    // å‘ç”Ÿäº†ä»€ä¹ˆï¼š

    // 0 å· æ‹¿åˆ° 16 å· çš„æ•°æ®ï¼Œä¸¤è€…æ¯”å¤§å°ï¼Œç•™ä¸‹å¤§çš„ã€‚

    // 1 å· æ‹¿åˆ° 17 å· çš„æ•°æ®ï¼Œä¸¤è€…æ¯”å¤§å°ã€‚

    // ...

    // 15 å· æ‹¿åˆ° 31 å· çš„æ•°æ®ï¼Œä¸¤è€…æ¯”å¤§å°ã€‚

    // ç»“æœï¼šæ­¤æ—¶ï¼Œå…¨ç»„æœ€å¤§çš„æ•°ï¼Œä¸€å®šå·²ç»è·‘åˆ°**å‰ 16 ä¸ªäººï¼ˆ0~15 å·ï¼‰**çš„æ‰‹é‡Œäº†ã€‚å 16 ä¸ªäººæ‰‹é‡Œè™½ç„¶ä¹Ÿæœ‰æ•°æ®ï¼Œä½†å·²ç»æ˜¯â€œåºŸç‰Œâ€äº†ã€‚
    // ç¬¬ 2 è½®ï¼šoffset = 8 (å³ 16 >> 1)
    // ä»£ç æ‰§è¡Œï¼šneighbor = __shfl_down_sync(..., local_max, 8)

    // å‘ç”Ÿäº†ä»€ä¹ˆï¼š

    // 0 å· æ‹¿åˆ° 8 å· çš„æ•°æ®ï¼ˆæ³¨æ„ï¼š8 å·æ­¤æ—¶æ‰‹é‡Œå·²ç»æ˜¯åŸæœ¬ 8 å·å’Œ 24 å·çš„èƒœè€…äº†ï¼‰ã€‚

    // 1 å· æ‹¿åˆ° 9 å· çš„æ•°æ®ã€‚

    // ...

    // 7 å· æ‹¿åˆ° 15 å· çš„æ•°æ®ã€‚

    // ç»“æœï¼šå…¨ç»„æœ€å¤§çš„æ•°ï¼Œç¼©å°åˆ°äº†**å‰ 8 ä¸ªäººï¼ˆ0~7 å·ï¼‰**çš„æ‰‹é‡Œã€‚
    for(int offset = 16; offset > 0; offset >>= 1) {
        int neighbnor = __shfl_down_sync(0xffffffff,local_max,offset);
        local_max = max(local_max,neighbnor);
    }
    // step3 :collect all warp results to shared memory
    // å‡è®¾ Block å¤§å°ä¸º 256ï¼Œåˆ™æœ‰ 8 ä¸ª Warpã€‚
    // æ¯ä¸ª Warp çš„ 0 å·çº¿ç¨‹(lane==0)æŒæœ‰è¯¥ Warp çš„æœ€å¤§å€¼ï¼Œå°†å…¶å†™å…¥å…±äº«å†…å­˜ã€‚
    __shared__ int warp_maxes[8];
    if(lane == 0) {
        warp_maxes[warpId] = local_max;
    }
    __syncthreads();

    // step4: the laset warp warp does the reduce for all warp_maxes
    // è®©ç¬¬ä¸€ä¸ªwarpï¼ˆwarpID = 0)æŠŠå…±äº«å†…å­˜çš„8ä¸ªå€¼å–å‡ºæ¥ï¼Œå†åšä¸€æ¬¡å½’çº¦
    // å› ä¸º8ä¸ªæ•°æ®åˆ†é…åˆ°ä¸åŒçš„çº¿ç¨‹é‡Œé¢ï¼Œæ‰€ä»¥éœ€è¦ç»Ÿä¸€åœ¨ä¸€èµ·
    int block_max = INT_MIN;
    if(warpId == 0) {
        if(lane < 8) { // å‰8ä¸ªçº¿ç¨‹å»æ‹¿ä¸œè¥¿ï¼Œå…¶ä½™ç©ºè½¬
            block_max = warp_maxes[lane];
        } 
        // å†æ¬¡ä½¿ç”¨ Shuffle è¿›è¡Œå½’çº¦
        for(int offset = 16; offset > 0; offset >>= 1) {
            int neighbor = __shfl_down_sync(0xffffffff,block_max,offset);
            block_max = max(block_max,neighbor);
        }
    }
    // step5: thread 0 update the global max
    // æ­¤æ—¶ lane 0 (ä¹Ÿå°±æ˜¯ tid 0) æŒæœ‰æ•´ä¸ª Block çš„æœ€å¤§å€¼
    if (tid == 0) {
        atomicMax(result, block_max);
    }

}
int main() {

    printf("lesson 3: ç»Ÿä¸€å†…å­˜ç®¡ç†æ±‚æœ€å¤§å€¼\n");

    // 1.generate dta;
    const int N = 200000000;
    printf("æ•°æ®å¤§å°ï¼š  %2.f MB \n\n", N * sizeof(int) / 1024.0 / 1024.0);

    // unified memory
    int* data,* gpu_result,*result_shared,*result_warp;
    CUDA_CHECK(cudaMallocManaged(&data,N * sizeof(int)));
    CUDA_CHECK(cudaMallocManaged(&gpu_result,sizeof(int)));
    CUDA_CHECK(cudaMallocManaged(&result_shared,sizeof(int)));
    CUDA_CHECK(cudaMallocManaged(&result_warp,sizeof(int)));
    srand(time(NULL));
    for(int i = 0; i < N; i++) {
        data[i] = rand() % 100000; // 0 - 99999
    }

    // è®¾å®šä¸€ä¸ªæœ€å¤§å€¼
    int know_max_pos = N / 2;
    data[know_max_pos] = 999999;

    printf("è®°ä½å•¦ ï¼š æœ€å¤§å€¼æ˜¯ 999999\n\n");

    clock_t cpu_start = clock();
    int cpu_max = findMaxCpu(data,N);
    clock_t cpu_end = clock();
    double cpu_time = (double)(cpu_end - cpu_start) / CLOCKS_PER_SEC * 1000;
    
    printf("CPUç»“æœ: %d (è€—æ—¶: %.2f ms)\n\n", cpu_max, cpu_time);


    
    // 3. å¿…é¡»åŒæ­¥ï¼ç¡®ä¿ä¸Šé¢ä¸¤æ­¥å½»åº•åšå®Œäº†ï¼Œå†å¼€å§‹è®¡æ—¶
    CUDA_CHECK(cudaDeviceSynchronize());
    printf("é¢„çƒ­å®Œæˆï¼å¼€å§‹çœŸæ­£çš„æ€§èƒ½æµ‹è¯•...\n\n");

    *gpu_result = INT_MIN;
    int threadsPerBlock = 256;
    // int blockPreGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    int blockPreGrid = 1024;

// =======================================================
    // ğŸš€ã€ä¿®æ­£ç‰ˆã€‘WSL2 ä¸“ç”¨é¢„çƒ­æ–¹æ¡ˆ
    // =======================================================
    int deviceId = 0;
    cudaGetDevice(&deviceId);
    printf("Debug: Current Device ID = %d (WSL2 ç¯å¢ƒå¿½ç•¥ Prefetch)\n", deviceId);

    printf("æ­£åœ¨é¢„çƒ­ GPU... (åˆ©ç”¨ Kernel è§¦å‘ç¼ºé¡µä¸­æ–­æ¬è¿æ•°æ®)\n");

    // 1. ã€å…³é”®ã€‘ä¸è¦ç”¨ cudaMemPrefetchAsyncï¼Œç›´æ¥è·‘ä¸€æ¬¡ Kernel
    // å½“ GPU è¯•å›¾è¯»å– data[i] æ—¶ï¼Œé©±åŠ¨ä¼šè‡ªåŠ¨æŠŠæ•°æ®ä» CPU æ¬åˆ° GPU L2/æ˜¾å­˜
    // è¿™æ¬¡è¿è¡Œä¼šå¾ˆæ…¢ï¼ˆå› ä¸ºåŒ…å«æ¬è¿æ—¶é—´ï¼‰ï¼Œæˆ‘ä»¬ä¸è®¡å…¥æˆç»©
    findMaxGpu_warp_shuffle<<<blockPreGrid, threadsPerBlock>>>(data, N, gpu_result);
    
    // 2. å¿…é¡»åŒæ­¥ï¼ç­‰å¾…æ¬è¿å’Œç¬¬ä¸€æ¬¡è®¡ç®—å½»åº•ç»“æŸ
    CUDA_CHECK(cudaDeviceSynchronize());
    
    printf("é¢„çƒ­å®Œæˆï¼æ•°æ®å·²åœ¨æ˜¾å­˜ä¸­ï¼Œå¼€å§‹çœŸæ­£çš„æ€§èƒ½æµ‹è¯•...\n\n");
    // =======================================================


    // --- ä¸‹é¢æ˜¯åŸæœ¬çš„è®¡æ—¶ä»£ç  (ä¿æŒä¸å˜) ---
    // æ­¤æ—¶æ•°æ®å·²ç»åœ¨æ˜¾å­˜é‡Œäº†ï¼Œç¬¬äºŒæ¬¡è¿è¡Œå°±ä¼šé£å¿«ï¼
   
    
    // 2. é¢„çƒ­ Kernel (æ¶ˆé™¤ç¬¬ä¸€æ¬¡å¯åŠ¨çš„å¼€é”€)
    // éšä¾¿è·‘ä¸€æ¬¡ï¼Œè®© GPU é†’è¿‡æ¥
    findMaxGpu_warp_shuffle<<<blockPreGrid, threadsPerBlock>>>(data, N, gpu_result);

    cudaEvent_t start1,stop1;
    CUDA_CHECK(cudaEventCreate(&start1));
    CUDA_CHECK(cudaEventCreate(&stop1));

    cudaEventRecord(start1);

    findMaxGpu_native<<<blockPreGrid,threadsPerBlock>>>(data,N,gpu_result);

    CUDA_CHECK(cudaEventRecord(stop1));

    cudaEventSynchronize(stop1);

    float gpu_time;
    CUDA_CHECK(cudaEventElapsedTime(&gpu_time,start1,stop1));
    cudaDeviceSynchronize();
    printf("GPU ç»“æœ: %d (è€—æ—¶: %.2f ms)\n\n", *gpu_result, gpu_time);
    
    *result_shared = INT_MIN;

    // å…±äº«å†…å­˜å¤§å°ï¼ˆåŠ¨æ€ç”³è¯·ï¼‰
    int shared_mem_size = threadsPerBlock * sizeof(int);
    
    cudaEvent_t start2,stop2;
    CUDA_CHECK(cudaEventCreate(&start2));
    CUDA_CHECK(cudaEventCreate(&stop2));

    cudaEventRecord(start2);

    findMaxGpu_shared<<<blockPreGrid,threadsPerBlock,shared_mem_size>>>(data,N,result_shared);

    CUDA_CHECK(cudaEventRecord(stop2));

    cudaEventSynchronize(stop2);

    float time_shared;
    CUDA_CHECK(cudaEventElapsedTime(&time_shared,start2,stop2));
    cudaDeviceSynchronize();
    printf("gpu_shared ç»“æœ: %d (è€—æ—¶: %.2f ms)\n\n", *result_shared, time_shared);

    cudaEvent_t start3,stop3;
    CUDA_CHECK(cudaEventCreate(&start3));
    CUDA_CHECK(cudaEventCreate(&stop3));

    cudaEventRecord(start3);

    findMaxGpu_warp_shuffle<<<blockPreGrid,threadsPerBlock>>>(data,N,result_warp);

    CUDA_CHECK(cudaEventRecord(stop3));

    cudaEventSynchronize(stop3);

    float time_warp;
    CUDA_CHECK(cudaEventElapsedTime(&time_warp,start3,stop3));
    cudaDeviceSynchronize();
    printf("gpu_warp ç»“æœ: %d (è€—æ—¶: %.2f ms)\n\n", *result_warp, time_warp);
    // å†…å­˜éœ€è¦é‡Šæ”¾æ‰
    CUDA_CHECK(cudaFree(data));
    CUDA_CHECK(cudaFree(gpu_result));
    CUDA_CHECK(cudaEventDestroy(start1));
    CUDA_CHECK(cudaEventDestroy(stop1));
    CUDA_CHECK(cudaFree(result_shared));
    CUDA_CHECK(cudaEventDestroy(start2));
    CUDA_CHECK(cudaEventDestroy(stop2));
    CUDA_CHECK(cudaFree(result_warp));
    CUDA_CHECK(cudaEventDestroy(start3));
    CUDA_CHECK(cudaEventDestroy(stop3));
    
}